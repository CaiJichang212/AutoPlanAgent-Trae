"""工具函数模块，提供日志配置、模型加载、文本处理和向量嵌入等通用功能。

该模块封装了多种 LLM 服务（ModelScope, SiliconFlow）的调用接口，
并提供了一些辅助函数，如 Markdown 转纯文本、加载提示词模板等。
"""
import json
import logging
import os
from typing import List, Optional
import urllib.request
from langchain_core.embeddings import Embeddings
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_qwq import ChatQwQ, ChatQwen
import random
import time
from dotenv import load_dotenv

# 加载 .env 文件
# 尝试在当前目录和上级目录寻找 .env
load_dotenv()
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

MODEL = "Qwen/Qwen3-30B-A3B-Instruct-2507"

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

MODELSCOPE_API_KEY_LIST = os.getenv("MODELSCOPE_API_KEYS", "").split(",")
# 过滤掉空字符串
MODELSCOPE_API_KEY_LIST = [key for key in MODELSCOPE_API_KEY_LIST if key]

SiliconFlow_API_KEY_LIST = os.getenv("SILICONFLOW_API_KEYS", "").split(",")
# 过滤掉空字符串
SiliconFlow_API_KEY_LIST = [key for key in SiliconFlow_API_KEY_LIST if key]

def setup_logger(name: Optional[str] = None, log_file: Optional[str] = None, level=logging.INFO, console_output: bool = True, clear_existing: bool = False):
    """设置 Logger，支持输出到控制台和文件。

    Args:
        name: Logger 名称。
        log_file: 日志文件路径。
        level: 日志级别。
        console_output: 是否输出到控制台。
        clear_existing: 是否清除现有的 Handler。

    Returns:
        配置好的 Logger 对象。
    """
    # 如果没有提供名字，或者名字为空，则配置根日志记录器
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # 如果要求清除现有 Handler
    if clear_existing:
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
    
    # 防止重复添加 Handler
    if not logger.handlers:
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        
        # 控制台 Handler
        if console_output:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            logger.addHandler(console_handler)
        
        # 文件 Handler
        if log_file:
            log_dir = os.path.dirname(log_file)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir)
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
            
    return logger

def _normalize_base_url(base_url: Optional[str]) -> Optional[str]:
    """规范化 API 基础 URL，确保以斜杠结尾。"""
    if not base_url:
        return base_url
    # Most LangChain OpenAI-compatible clients expect a trailing slash, e.g. ".../v1/".
    return base_url if base_url.endswith("/") else base_url + "/"


def get_model_from_name(
    model: str = MODEL,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    late_time: float = 0.5,
    **kwargs,
):
    """根据模型名称自动选择合适的加载函数。

    Args:
        model: 模型名称。
        api_key: API 密钥。
        base_url: API 基础 URL。
        late_time: 调用前的延迟时间（秒），用于频率限制。
        **kwargs: 传递给 LLM 客户端的其他参数。

    Returns:
        初始化的 LLM 对象。
    """
    if "instruct" in model.lower():
        return llm_qwen(model=model, api_key=api_key, base_url=base_url, late_time=late_time, **kwargs)
    elif "thinking" in model.lower():
        return llm_qwq(model=model, api_key=api_key, base_url=base_url, late_time=late_time, **kwargs)
    else:
        return llm_modelscope(model=model, api_key=api_key, base_url=base_url, late_time=late_time, **kwargs)

def llm_qwq(model: str = MODEL,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    late_time: float = 0.5,
    **kwargs,
):
    """加载 QwQ (Thinking) 模型。"""
    if not api_key:
        api_key = random.choice(MODELSCOPE_API_KEY_LIST)
    if not base_url:
        base_url = "https://api-inference.modelscope.cn/v1/"
    base_url = _normalize_base_url(base_url)
    time.sleep(late_time)
    
    # 默认开启Thinking
    model_think = ChatQwQ(
        model = model,
        base_url = base_url,
        api_key = api_key,
        **kwargs,
    )
    
    return model_think

def llm_qwen(
    model: str = MODEL,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    late_time: float = 0.5,
    **kwargs,
):
    """加载 Qwen (Instruct) 模型。"""
    if not api_key:
        api_key = random.choice(MODELSCOPE_API_KEY_LIST)
    if not base_url:
        base_url = "https://api-inference.modelscope.cn/v1/"
    base_url = _normalize_base_url(base_url)
    time.sleep(late_time)
    
    # 确保 enable_thinking 在非流式调用下为 False
    if 'enable_thinking' not in kwargs:
        kwargs['enable_thinking'] = False
        
    model_think = ChatQwen(
        model=model,
        base_url=base_url,
        api_key=api_key,
        **kwargs,
    )
    
    return model_think

def llm_modelscope(
    model: str = MODEL,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    late_time: float = 0.5,
    **kwargs,
):
    """加载 ModelScope 上的 OpenAI 兼容模型。"""
    if not api_key:
        api_key = random.choice(MODELSCOPE_API_KEY_LIST)
    if not base_url:
        base_url = "https://api-inference.modelscope.cn/v1/"
    base_url = _normalize_base_url(base_url)
    time.sleep(late_time)
    
    llm = ChatOpenAI(
        model=model,
        api_key=api_key,
        base_url=base_url,
        **kwargs,
    )
    
    return llm

def llm_siliconflow(
    model: str = MODEL,
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    late_time: float = 0.5,
    **kwargs,
):
    """加载 SiliconFlow 上的 OpenAI 兼容模型。"""
    if not api_key:
        api_key = random.choice(SiliconFlow_API_KEY_LIST)
    if not base_url:
        base_url = "https://api.siliconflow.cn/v1/"
    base_url = _normalize_base_url(base_url)
    time.sleep(late_time)
    
    llm = ChatOpenAI(
        model=model,
        api_key=api_key,
        base_url=base_url,
        **kwargs,
    )
    return llm


import re

def md2txt(md_text: str) -> str:
    """将 Markdown 文本转换为纯文本。

    通过正则表达式移除代码块、标题、粗体、链接、列表等 Markdown 标记。

    Args:
        md_text: 包含 Markdown 格式的文本。

    Returns:
        转换后的纯文本。
    """
    # 移除代码块 (```code```)
    plain_text = re.sub(r'```.*?```', '', md_text, flags=re.DOTALL)
    
    # 移除行内代码 (`code`)
    plain_text = re.sub(r'`(.*?)`', r'\1', plain_text)
    
    # 移除标题标记 (#, ##, ### 等)
    plain_text = re.sub(r'^#+\s*', '', plain_text, flags=re.MULTILINE)
    
    # 移除粗体标记 (**text** 或 __text__)
    plain_text = re.sub(r'\*\*(.*?)\*\*|__(.*?)__', r'\1\2', plain_text)
    
    # 移除斜体标记 (*text* 或 _text_)
    plain_text = re.sub(r'\*(.*?)\*|_(.*?)_', r'\1\2', plain_text)
    
    # 移除链接和图片
    # 先处理图片 (![alt](url))
    plain_text = re.sub(r'!\[.*?\]\(.*?\)', '', plain_text)
    # 再处理链接 ([text](url))
    plain_text = re.sub(r'\[.*?\]\(.*?\)', '', plain_text)
    
    # 移除引用标记 (>)
    plain_text = re.sub(r'^>\s*', '', plain_text, flags=re.MULTILINE)
    
    # 移除列表标记 (- *, + 或数字.)
    plain_text = re.sub(r'^\s*[-*+]\s*', '', plain_text, flags=re.MULTILINE)
    plain_text = re.sub(r'^\s*\d+\.\s*', '', plain_text, flags=re.MULTILINE)
    
    # 移除水平线 (---, *** 或 ___)
    plain_text = re.sub(r'^[-*_]{3,}$', '', plain_text, flags=re.MULTILINE)
    
    # 移除表格格式
    # 首先移除表格分隔线
    plain_text = re.sub(r'^[-:|\s]+$', '', plain_text, flags=re.MULTILINE)
    # 然后移除表格行
    plain_text = re.sub(r'^\|.*?\|$', '', plain_text, flags=re.MULTILINE)
    
    # 移除多余的空白行
    plain_text = '\n'.join(line.strip() for line in plain_text.splitlines() if line.strip())
    
    return plain_text


def load_prompt(prompt_name: str) -> str:
    """从 agent/prompts 目录加载 prompt 模板。

    Args:
        prompt_name: 提示词文件的名称（不含扩展名）。

    Returns:
        文件内容字符串。

    Raises:
        FileNotFoundError: 如果提示词文件不存在。
    """
    prompt_path = os.path.join(os.path.dirname(__file__), 'prompts', f"{prompt_name}.txt")
    if not os.path.exists(prompt_path):
        raise FileNotFoundError(f"Prompt file not found: {prompt_path}")
    with open(prompt_path, 'r', encoding='utf-8') as f:
        return f.read()


class SiliconFlowEmbeddings(BaseModel, Embeddings):
    """硅基流动词向量模型适配器。

    Attributes:
        model: 要使用的模型名称。
        api_key: API 密钥。
        base_url: API 的基础 URL。
        batch_size: 每批处理的文本数量。
    """
    
    model: str = Field(default="BAAI/bge-m3", description="要使用的模型名称")
    api_key: Optional[str] = Field(default=None, description="API密钥")
    base_url: str = Field(default="https://api.siliconflow.cn/v1/embeddings", description="API的基础URL")
    batch_size: int = Field(default=4, description="每批处理的文本数量")
    
    def get_api_key(self):
        """获取并随机选择一个 API 密钥。"""
        if not self.api_key:
            self.api_key = random.choice(SiliconFlow_API_KEY_LIST)
        
        return self.api_key

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """为多个文本生成嵌入向量，支持批量处理。

        Args:
            texts: 要嵌入的文本列表。

        Returns:
            嵌入向量列表。
        """
        all_embeddings = []
        
        # 分批处理文本
        n = len(texts)
        for i in range(0, n, self.batch_size):
            batch_texts = texts[i:min(i + self.batch_size, n)]
            
            # 硅基流API的请求头
            headers = {
                "Authorization": f"Bearer {self.get_api_key()}",
                "Content-Type": "application/json"
            }
            
            # 构造请求数据
            data = {
                "model": self.model,
                "input": batch_texts,
                "encoding_format": "float"
            }
            
            # 发送POST请求
            request = urllib.request.Request(
                self.base_url,
                data=json.dumps(data).encode('utf-8'),
                headers=headers
            )
            
            try:
                with urllib.request.urlopen(request) as response:
                    result = json.loads(response.read().decode('utf-8'))
                    # 收集嵌入向量
                    all_embeddings.extend([item['embedding'] for item in result['data']])
            except Exception as e:
                print(f"总共{n}条文本，处理第{i}到{min(i + self.batch_size, n)}条文本时出错: {str(e)}")
                for idx in range(i, min(i + self.batch_size, n)):
                    print(idx, texts[idx])
                raise Exception(f"请求硅基流API时出错: {str(e)}")
        
        return all_embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """为单个文本生成嵌入向量。

        Args:
            text: 要嵌入的文本。

        Returns:
            嵌入向量。
        """
        # 对于单个文本，我们仍然使用embed_documents方法
        return self.embed_documents([text])[0]
